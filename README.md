# mini-ml-project-lavi
Logistic Regression implemented from scratch in Python (NumPy)
Manual implementation of logistic regression

Sigmoid function, loss computation, and gradient descent

Feature normalization and bias term handling

Accuracy evaluation without prebuilt ML libraries
Key Steps

Data Loading: Load and clean the dataset using pandas.

Preprocessing: Normalize input features for stable convergence.

Model Building: Implement the logistic regression formula manually.

Optimization: Apply gradient descent to minimize loss.

Evaluation: Compare predicted outcomes with true labels.
Concepts Learned

How gradient descent updates parameters

Why normalization and bias are essential

How logistic regression separates classes

How to build ML logic manually (no sklearn magic)


Author

üë©‚Äçüíª Lavanya
MTech student in Computational Biology, exploring the intersection of machine learning and bioinformatics.
